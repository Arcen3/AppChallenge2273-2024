{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Best Fit Lines for GFP export\n",
    "\n",
    "To evaluate if Kinesore is able to generate sufficient effect on the cells to control the export rate of GFP-TNF out of the cell, we assume that at maximum relative fluorescence in our plot would be the point in time at which accummulation in the golgi is maximum. This means that from that image onwards, there is only export of GFP-TNF out of the cell.\n",
    "\n",
    "It is also assumed that the concentration of GFP-TNF is positively related to the level of fluorescence that is observed, and any decrease in fluorescence level is due to GFP export and not due to degradation.\n",
    "\n",
    "We will use a simple linear relation to evaluate if the rate of decrease of fluorescence is related to the concentration of drug that is added to the media of the plates.\n",
    "\n",
    "## The Math\n",
    "To do linear regression, we used `scipy.stats.linregress` to find the gradient and intercept of the best fit line, as well as the $r^2$ values for our best fit line.\n",
    "\n",
    "However, to better our understanding of how linear regression can be done, we have also created our own linear regression function using the gradient descent algorithm.\n",
    "\n",
    "The idea behind gradient descent algorithm is to minimise the value of the function that is the input by taking steps in the opposite direction of the gradient. The minima of the function would be found when the gradient of the function, $f'(x)$ is 0. If the gradient is increasing in the positive x direction, then we want to take a step in the opposite x direction where the gradient is decreasing, and vice versa. \n",
    "\n",
    "Mathematically, this is represented as:\n",
    "$$\n",
    "p_{n+1} = p_{n} - \\mu\\nabla p(n) \n",
    "$$\n",
    "where p refers to the function to be minimised, and $\\mu$ is the step size, or learning rate as others may call it.\n",
    "\n",
    "$\\nabla p(n)$ is the gradient vector of function $p(n)$, where its direction points towards the direction of maximum increase.\n",
    "\n",
    "As we approach the minima of the function, the gradient becomes increasingly small, leading to the overall step per iteration of the algorithm becoming smaller as well.\n",
    "\n",
    "This can be illustrated in a graph visually, which we have taken from an external source. The red lines show how the gradient descent algorithm attempts to move towards the minima of the input function, in this case, a quadratic equation, with different step sizes. In general, a larger step size may be able to reach the minima faster, but it may also overshoot the minima as can be see n in the rightmost graph in the image.\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*GR914FuA4pVTTXEpVDJ2Ng.png)\n",
    "\n",
    "For further reading, see [Gradient Descent Algorithm explained](https://towardsdatascience.com/gradient-descent-algorithm-a-deep-dive-cf04e8115f21).\n",
    "\n",
    "## Mean Square Errors, MSE\n",
    "The function that we will use to evaluate whether the line is a good fit for the graph would be the mean squared errors function. We will refer to this function as the cost function for gradient descent algorithm.\n",
    "\n",
    "$$\n",
    "\\mathrm{Mean Squared Errors, J} = \\dfrac{1}{n} \\sum^n_{n=0} (\\bar{y} - y_i)^2 \\tag{1}\n",
    "$$\n",
    "\n",
    "where $n$ is total number of data points, $\\bar{y}$ is the predicted y values, and $y_i$ is the original y values.\n",
    "\n",
    "$\\bar{y} - y_i$ is the residual, or the error, between the predicted y values and the actual data input.\n",
    "\n",
    "For linear regression, $\\bar{y}$ would be represented by $\\bar{y} = mx_i + c$ where $m$ is the gradient and $c$ is the intercept.\n",
    "\n",
    "To obtain the best fit line, we would want the predicted best fit line to have the smallest possible mean squared error. In other words, we want to minimise equation (1). This is where gradient descent algorithm would come in to help minimise the function. In order to use the algorithm, however, the partial derivatives with respect to the constant and the gradient of the graph needs to be found. Simply put, we need to know how does the MSE function change as the gradient and constant are varied individually.\n",
    "\n",
    "The partial derivatives for the cost function can be found below:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial c} = \\frac{2}{n} \\sum^n_{n=0}(c + mx_i - y_i) \\tag{2}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial m} = \\frac{2}{n} \\sum^n_{n=0}(c + mx_i - y_i)(x_i) \\tag{3}\n",
    "$$\n",
    "\n",
    "These are found in `djdc` and `djdm`, and the gradient descent algorithm is written in `get_lineEqn`. \n",
    "\n",
    "## Explaining the code of gradient descent\n",
    "`diff1` and `diff2` are the gradients multiplied by the step size, $\\mu$, and compared against a tolerance value. If both `diff1` and `diff2` are less than the tolerance value of $1e^{-4}$, then the function is stopped and the values of the gradient and intercept are returned.\n",
    "\n",
    "`max_iter` controls the maximum number of times that the function will loop and calculate the next step of the gradient and intercept. This is set to prevent the function from running into an issue where the tolerance value may be set too low and the function overshoots the minimum point. \n",
    "\n",
    "Initialisation values for our linear regression function are $m$ = -1 and $c = 1$. $m$ is set to be negative as the export of GFP out of the cell would lead to a decrease in the fluorescence values, and therefore a downward trend on the graph. Hence, a negative gradient should be expected. $c$ is set to be 1 as the maximum relative fluorescence is 1, which at t = 0 should be maximum, and therefore the intercept of the graph should be at 1.\n",
    "\n",
    "## Evaluating the fit of the lines\n",
    "To evaluate how well these lines fit to the data points, the $r^2$ value is calculated. This is done using `r2calc` function. The $r^2$ function can be found below:\n",
    "\n",
    "$$\n",
    "r^2 = 1 - \\frac{\\mathrm{Sum of squares of residuals}}{\\mathrm{Total sum of squares}}\n",
    "$$\n",
    "\n",
    "## Comparison against scipy's linregress\n",
    "In general, we observe that scipy's function is able to provide better fits for the linear equations, as the $r^2$ values given by `linregress` is consistently higher than that of our own `get_lineEqn` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6vXvEhBsEQdF"
   },
   "outputs": [],
   "source": [
    "import os, glob, shutil, cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from scipy.stats import linregress\n",
    "from skimage.filters import threshold_otsu, threshold_yen, try_all_threshold, threshold_minimum, threshold_isodata\n",
    "import skimage.measure as measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eOS87E7aEtzH"
   },
   "source": [
    "# Extracting frames from video using cv2 package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oz3sZ_OqEdF2"
   },
   "outputs": [],
   "source": [
    "#find videos\n",
    "print(f'Current directory: {os.getcwd()}')\n",
    "\n",
    "path_to_videos = glob.glob(os.path.join('Videos','*.avi'))\n",
    "print(path_to_videos, '-'*10, sep = '\\n')\n",
    "#create required directories\n",
    "def makefolders(path):\n",
    "    folder = os.path.split(path) #create folders for extracting all images\n",
    "    folder = os.path.splitext(folder[-1])\n",
    "    folder_create = os.path.join('Videos',folder[0])\n",
    "    if os.path.exists(folder_create) == False:\n",
    "        os.mkdir(folder_create)\n",
    "    else:\n",
    "        pass\n",
    "    return folder_create\n",
    "\n",
    "#navigate into folder for the image and save images\n",
    "def saveimages(path, dir_name):\n",
    "    cam = cv2.VideoCapture(path)\n",
    "    count, success = 0, True\n",
    "    video_index = []\n",
    "    while success:\n",
    "        success, image = cam.read()\n",
    "        if not cam.isOpened():\n",
    "            print(f\"Error: Could not open video file {path}\")\n",
    "        os.chdir(dir_name)\n",
    "        if success:\n",
    "            folder = os.path.split(dir_name)\n",
    "            frame = f'{folder[-1]}_frame_{count:02}.jpg'\n",
    "            video_index.append(frame)\n",
    "            if os.path.exists(frame) == False:\n",
    "                cv2.imwrite(frame, image)\n",
    "                print(f'{frame} successfully saved')\n",
    "                count+=1\n",
    "            else:\n",
    "                print(f'{frame} already exists, skipping save')\n",
    "                count+=1\n",
    "        else:\n",
    "            print('End of file')\n",
    "        os.chdir(os.path.join('..','..'))\n",
    "    cam.release()\n",
    "    print(f'Current directory: {os.getcwd()} \\n Completed {path}\\n--------------------')\n",
    "    return video_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gg9dqj-_Ey6L"
   },
   "outputs": [],
   "source": [
    "video_indexes, folder_indexes = [], []\n",
    "vf_dict = {}\n",
    "for path in path_to_videos:\n",
    "    dir_name = makefolders(path)\n",
    "    folder_indexes.append(dir_name)\n",
    "    img_names = saveimages(path, dir_name)\n",
    "    video_indexes.append(img_names)\n",
    "    vf_dict[os.path.split(dir_name)[-1]] = img_names\n",
    "\n",
    "#show structure of the dictionary\n",
    "for key, item in vf_dict.items():\n",
    "    print(key, item, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAwURZlkE5Er"
   },
   "source": [
    "# Process fluorescence data - First pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vy_AyRYCE2NX"
   },
   "outputs": [],
   "source": [
    "# Functions for extracting and plotting the raw data\n",
    "cwd = os.getcwd() #getting current working directory\n",
    "\n",
    "folders_to_process = ('LipoKDEL1ug_biotin_no drug_live_5min1h',  'LipoKDEL1ug_biotin_drug25uM_live_5min1h',\n",
    "                      'XtremeStr-li1.5ug_biotin_drug50uM_live_5min1h',\n",
    "                      '0.5ugDNA_drug10uM_5min45min_1', '0.75ugDNA_drug10uM_5min45min_1', '1ugDNA_drug10uM_5min45min_1')\n",
    "\n",
    "region_of_interest = {'0.5ugDNA_drug10uM_5min45min_1': [(300,500, 400,600)],\n",
    "           '0.75ugDNA_drug10uM_5min45min_1': [(300,475, 375,550),(690,780, 400,500), (530,630, 530,630)],\n",
    "           '1ugDNA_drug10uM_5min45min_1': [(400,550, 180,300),(695,790, 655,725)],\n",
    "           'LipoKDEL1ug_biotin_drug25uM_live_5min1h': [(625,740, 600,720)],\n",
    "           'LipoKDEL1ug_biotin_no drug_live_5min1h': [(550,690, 450,600)],\n",
    "           'XtremeStr-li1.5ug_biotin_drug50uM_live_5min1h': [(285,400, 70,150),(615,675, 650,715), (170,260, 970,1024)]\n",
    "}\n",
    "\n",
    "golgi_frame = {'0.5ugDNA_drug10uM_5min45min_1': '0.5ugDNA_drug10uM_5min45min_1_frame_03.jpg',\n",
    "           '0.75ugDNA_drug10uM_5min45min_1': '0.75ugDNA_drug10uM_5min45min_1_frame_02.jpg',\n",
    "           '1ugDNA_drug10uM_5min45min_1': '1ugDNA_drug10uM_5min45min_1_frame_03.jpg',\n",
    "           'LipoKDEL1ug_biotin_drug25uM_live_5min1h': 'LipoKDEL1ug_biotin_drug25uM_live_5min1h_frame_06.jpg',\n",
    "           'LipoKDEL1ug_biotin_no drug_live_5min1h': 'LipoKDEL1ug_biotin_no drug_live_5min1h_frame_04.jpg',\n",
    "           'XtremeStr-li1.5ug_biotin_drug50uM_live_5min1h': 'XtremeStr-li1.5ug_biotin_drug50uM_live_5min1h_frame_06.jpg'\n",
    "              }\n",
    "\n",
    "#creating a function called extract_fluorescenceData, to loop through the 7 different folders.\n",
    "def extract_fluorescenceData(folder_path, img_order, resolutions):\n",
    "    total_fluorescence = [] #empty list to add the max fluoresence later and plot\n",
    "    subdir_path = os.path.join(cwd,'Videos', folder_path) #create path to directory in the iteration\n",
    "\n",
    "    if os.path.isdir(subdir_path): #checking if subdirectory path exist\n",
    "        for img in img_order:\n",
    "            img_path = os.path.join(subdir_path, img)\n",
    "            if os.path.exists(img_path): #filter for only .jpg files inside subdir_path\n",
    "                a=plt.imread(img_path) #need save plt.imread to a variable, if not cannot plot downstream\n",
    "                img_gray = rgb2gray(a) #converting the img into grayscale\n",
    "                y1, y2, x1, x2 = resolutions\n",
    "                cropped_img = img_gray[y1:y2, x1:x2]\n",
    "                total_fluorescence.append(cropped_img.sum()) #sum up signal inside individual frames and append into total_fluorascence\n",
    "    else:\n",
    "        print(f'Subdirectory {video_folders} not found')\n",
    "    return total_fluorescence #return here so can use in \"histogrammer\" function. this variable will be 'video1' in histogrammer function\n",
    "\n",
    "def histogrammer(video1, n, i=0, label = False): #video1 is an array of the max fluorescence values, i simply stands for index\n",
    "    video1_normalise = video1/max(video1) #normalising to highest sum fluorescent signal in the frames.\n",
    "    name = os.path.split(n) #split it by \\\\ into index, where [0] = your directory and [i] in this case is folder names\n",
    "    x = range(1, len(video1)+1) #plotting frame 1 to n+1\n",
    "\n",
    "    #plotting segment\n",
    "    if label == True:\n",
    "        plt.plot(x, video1_normalise, linestyle = 'dashed', marker = 'o', label = 'Original Data') #marker is the data point, marked as circle.\n",
    "    else:\n",
    "        plt.plot(x, video1_normalise, linestyle = 'dashed', marker = 'o', label = f'{name} ROI {i}')\n",
    "    #Labels & aesthetics\n",
    "    # plt.xticks(x) #this makes it show every tick in X axis\n",
    "    plt.xlabel('Frame number', fontsize = 10)\n",
    "    plt.ylabel('Total fluorescence signal', fontsize = 10)\n",
    "    plt.grid(alpha = .25)\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YtI1q2F0FDji"
   },
   "outputs": [],
   "source": [
    "longest_video = 0\n",
    "plt.figure(figsize =(20,6))\n",
    "for key in region_of_interest.keys():\n",
    "    for i in range(len(region_of_interest[key])):\n",
    "        video1 = extract_fluorescenceData(key, vf_dict[key], region_of_interest[key][i])\n",
    "        if longest_video < len(video1):\n",
    "            longest_video = len(video1)\n",
    "        histogrammer(video1, key, i)\n",
    "plt.title('Graph of all regions of interest', fontsize = 10)\n",
    "plt.xticks(np.arange(1,longest_video+1))\n",
    "plt.legend(loc = 'upper right', bbox_to_anchor = (1.5,1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'Graph of all regions of interest', format = 'jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8-TfedmFH8j"
   },
   "source": [
    "# Attempting to assess the cropping of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08WDQM-JFExr"
   },
   "outputs": [],
   "source": [
    "#goal: identify green regions and calculate area to intensity ratio for lipoKDEL1ug_biotin_drug25uM\n",
    "video = {'LipoKDEL1ug_biotin_drug25uM_live_5min1h': (625,740, 600,720)}\n",
    "\n",
    "img_path = 'LipoKDEL1ug_biotin_drug25uM_live_5min1h_frame_03.jpg'\n",
    "img = plt.imread(os.path.join('Videos',list(video.keys())[0], img_path))\n",
    "img = img[625:740,600:720]\n",
    "\n",
    "plt.imshow(img)\n",
    "\n",
    "img_grey = rgb2gray(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_8LqkwHtFUDQ"
   },
   "outputs": [],
   "source": [
    "threshold = threshold_minimum(img_grey)\n",
    "img_binarised = img_grey < threshold\n",
    "\n",
    "img_labelled = measure.label(img_binarised.astype('uint8'))\n",
    "plt.imshow(img_labelled)\n",
    " # measure.label() requires an image of type int\n",
    "img_labelled = measure.label(img_binarised.astype('uint8'))\n",
    "region_info = measure.regionprops(img_labelled)\n",
    "print(region_info[0].area)\n",
    "\n",
    "no_of_regions = len(region_info)\n",
    "\n",
    "for count, region in enumerate(region_info):\n",
    "    print('-'*10, f'Region {count}', '-'*10)\n",
    "    print(f'Centre\\t: {region.centroid}')\n",
    "    print(f'Area\\t: {region.area}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l7VFhGtEFNFK"
   },
   "outputs": [],
   "source": [
    "img_masked = img_labelled == 1\n",
    "plt.imshow(img_masked)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ReXYViaXFYxF"
   },
   "outputs": [],
   "source": [
    "def ratio_Data(folder_path, img_order, resolutions): #attempting to find fluorescence/area ratio\n",
    "    total_fluorescence, areas = [], []\n",
    "    subdir_path = os.path.join(cwd,'Videos', folder_path) #create path to directory in the iteration\n",
    "\n",
    "    if os.path.isdir(subdir_path): #checking if subdirectory path exist\n",
    "        for img in img_order:\n",
    "            img_path = os.path.join(subdir_path, img)\n",
    "            if os.path.exists(img_path):\n",
    "            # if img.lower().endswith('.jpg'): #filter for only .jpg files inside subdir_path\n",
    "                a=plt.imread(img_path) #need save plt.imread to a variable, if not cannot plot downstream\n",
    "                img_gray = rgb2gray(a) #converting the img into grayscale\n",
    "                y1, y2, x1, x2 = resolutions\n",
    "                cropped_img = img_gray[y1:y2, x1:x2]\n",
    "\n",
    "                try:\n",
    "                    threshold = threshold_minimum(cropped_img)\n",
    "                    binarised_img = cropped_img < threshold\n",
    "                    img_labelled = measure.label(binarised_img.astype('uint8'))\n",
    "                    region_info = measure.regionprops(img_labelled)\n",
    "\n",
    "                    total_fluorescence.append(cropped_img.sum()) #sum up signal inside individual frames and append into total_fluorascence\n",
    "                    areas.append((y2-y1)*(x2-x1) - region_info[0].area)\n",
    "                except RuntimeError:\n",
    "                    print(f'Error with {img} image')\n",
    "                    pass\n",
    "    else:\n",
    "        print(f'Subdirectory {video_folders} not found')\n",
    "    ratio = np.array(total_fluorescence)/np.array(areas)\n",
    "    return ratio\n",
    "\n",
    "def overlay_threshold(folder_path, img_order, resolutions, return_base = True):\n",
    "    total_fluorescence, areas = [], []\n",
    "    subdir_path = os.path.join(cwd,'Videos', folder_path) #create path to directory in the iteration\n",
    "    y1, y2, x1, x2 = resolutions\n",
    "    overlay = np.zeros((y2-y1,x2-x1))\n",
    "\n",
    "    if os.path.isdir(subdir_path): #checking if subdirectory path exist\n",
    "        for img in img_order:\n",
    "            img_path = os.path.join(subdir_path, img)\n",
    "            if os.path.exists(img_path):\n",
    "                a=plt.imread(img_path) #need save plt.imread to a variable, if not cannot plot downstream\n",
    "                img_gray = rgb2gray(a) #converting the img into grayscale\n",
    "                cropped_img = img_gray[y1:y2, x1:x2]\n",
    "                cropped_img = noise_remove(cropped_img)\n",
    "                overlay+=cropped_img\n",
    "\n",
    "    else:\n",
    "        print(f'Subdirectory {video_folders} not found')\n",
    "    if return_base == True:\n",
    "        return extract_Data(folder_path, img_order, resolutions, overlay), overlay\n",
    "    else:\n",
    "        return overlay\n",
    "\n",
    "def extract_Data(folder_path, img_order, resolutions, overlay, use_threshold = False, reference = None):\n",
    "    total_fluorescence = [] #empty list to add the max fluoresence later and plot\n",
    "    subdir_path = os.path.join(cwd,'Videos', folder_path) #create path to directory in the iteration\n",
    "    if use_threshold == True and reference != None:\n",
    "        threshold = extract_threshold(folder_path, resolutions, reference)\n",
    "\n",
    "    if os.path.isdir(subdir_path): #checking if subdirectory path exist\n",
    "        for img in img_order:\n",
    "            img_path = os.path.join(subdir_path, img)\n",
    "            if os.path.exists(img_path): #filter for only .jpg files inside subdir_path\n",
    "                a=plt.imread(img_path) #need save plt.imread to a variable, if not cannot plot downstream\n",
    "                img_gray = rgb2gray(a) #converting the img into grayscale\n",
    "                y1, y2, x1, x2 = resolutions\n",
    "                cropped_img = img_gray[y1:y2, x1:x2]\n",
    "                cropped_img = noise_remove(cropped_img)\n",
    "                if use_threshold == True:\n",
    "                    cropped_img[cropped_img < threshold] = 0\n",
    "                cropped_img *= overlay\n",
    "                total_fluorescence.append(cropped_img.sum()) #sum up signal inside individual frames and append into total_fluorascence\n",
    "    else:\n",
    "        print(f'Subdirectory {video_folders} not found')\n",
    "    return total_fluorescence\n",
    "\n",
    "def extract_thresholdData(folder_path, img_order, resolutions, reference):\n",
    "    total_fluorescence = [] #empty list to add the max fluoresence later and plot\n",
    "    subdir_path = os.path.join(cwd,'Videos', folder_path) #create path to directory in the iteration\n",
    "    threshold = extract_threshold(folder_path, resolutions, reference)\n",
    "    y1, y2, x1, x2 = resolutions\n",
    "\n",
    "    if os.path.isdir(subdir_path): #checking if subdirectory path exist\n",
    "        for img in img_order:\n",
    "            img_path = os.path.join(subdir_path, img)\n",
    "            if os.path.exists(img_path): #filter for only .jpg files inside subdir_path\n",
    "                a=plt.imread(img_path) #need save plt.imread to a variable, if not cannot plot downstream\n",
    "                img_gray = rgb2gray(a) #converting the img into grayscale\n",
    "                cropped_img = img_gray[y1:y2, x1:x2]\n",
    "                cropped_img[cropped_img<threshold] = 0\n",
    "                total_fluorescence.append(cropped_img.sum()) #sum up signal inside individual frames and append into total_fluorascence\n",
    "    else:\n",
    "        print(f'Subdirectory {video_folders} not found')\n",
    "    return total_fluorescence\n",
    "\n",
    "def extract_threshold(folder_path, resolutions, reference):\n",
    "    ref_path = os.path.join(cwd, 'Videos', folder_path, reference)\n",
    "    img_ref = plt.imread(ref_path)\n",
    "\n",
    "    #reference threshold\n",
    "    img_ref = rgb2gray(img_ref)\n",
    "    y1, y2, x1, x2 = resolutions\n",
    "    img_ref_cropped = img_ref[y1:y2, x1:x2]\n",
    "    threshold = threshold_isodata(img_ref_cropped)\n",
    "    return threshold\n",
    "\n",
    "def power_overlay(overlay):\n",
    "    overlay = overlay**4\n",
    "    return overlay\n",
    "\n",
    "def norm_overlay(overlay):\n",
    "    overlay = overlay/np.max(overlay)\n",
    "    return overlay\n",
    "\n",
    "def get_label(filepath):\n",
    "    # x=list(region_of_interest.keys())[4]\n",
    "    label=[fragments for fragments in filepath.split('_') if 'drug' in fragments]\n",
    "    return label[0].upper()\n",
    "\n",
    "def noise_remove(img):\n",
    "    mask = img < 0.15\n",
    "    img[mask] = 0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hun3EGAoFQCe"
   },
   "outputs": [],
   "source": [
    "# This cycles through all video folders and creates the graphs\n",
    "for key in region_of_interest:\n",
    "    for i in range(len(region_of_interest[key])):\n",
    "        video1 = extract_fluorescenceData(key, vf_dict[key], region_of_interest[key][i])\n",
    "\n",
    "        #first overlay without any configuration to heat map\n",
    "        img_overlay, overlay = overlay_threshold(key, vf_dict[key], region_of_interest[key][i])\n",
    "        img_overlay = img_overlay/max(img_overlay)\n",
    "\n",
    "        #increasing the heat map by power of 4, not 2. squared is just an old name and im lazy\n",
    "        overlay1 = power_overlay(overlay)\n",
    "        img_squared = extract_Data(key, vf_dict[key], region_of_interest[key][i], overlay1)\n",
    "        img_squared = img_squared/max(img_squared)\n",
    "\n",
    "        #this is normalising the heat map, but it does the same as the first function\n",
    "        overlay2 = norm_overlay(overlay)\n",
    "        img_norm = extract_Data(key, vf_dict[key], region_of_interest[key][i], overlay2)\n",
    "        img_norm = img_norm/max(img_norm)\n",
    "\n",
    "        #fluorescence of ratio\n",
    "        ratio_f = ratio_Data(key, vf_dict[key], region_of_interest[key][i])\n",
    "        ratio_f = ratio_f/max(ratio_f)\n",
    "\n",
    "        img_mask = extract_thresholdData(key, vf_dict[key], region_of_interest[key][i], golgi_frame[key])\n",
    "        img_mask = img_mask/max(img_mask)\n",
    "\n",
    "        threshold_weighted = extract_Data(key, vf_dict[key], region_of_interest[key][i], overlay1,\n",
    "                                          use_threshold = True, reference = golgi_frame[key])\n",
    "        threshold_weighted = threshold_weighted/max(threshold_weighted)\n",
    "\n",
    "        frames = np.arange(1,len(img_overlay)+1)\n",
    "        plt.figure(figsize = (8,4))\n",
    "        plt.plot(frames, img_overlay, label = \"Linear\", linestyle = 'solid', marker = '*')\n",
    "        plt.plot(frames, img_squared, label = \"Powered\", linestyle = 'solid', marker = 'v')\n",
    "        plt.plot(frames, ratio_f, label = 'Fluorescence/Area', linestyle = 'solid', marker = 's')\n",
    "        plt.plot(frames, img_mask, label = 'Threshold', linestyle = 'solid', marker = 'p')\n",
    "        plt.plot(frames, threshold_weighted, label = \"Threshold and Power weight\", linestyle = 'solid', marker = 'P')\n",
    "        histogrammer(video1, key, i, label = True) #reusing previous code\n",
    "        plt.title(f'{key} Region of Interest {i}')\n",
    "        plt.legend(loc = 'upper right', bbox_to_anchor = (1.38,1))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{key} Region of Interest {i}', format = \"jpg\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OY7lG5vIFh4d"
   },
   "source": [
    "#Assessing the rate of export of TNF\n",
    "Likely will require data on how fluorescence levels correspond to GFP levels to create a calibration curve.\n",
    "\n",
    "While we are not able to assess exactly how fast it is exported and express it in terms of concentration per unit time, we can still assess whether the rate of export is linearly related or if other mathematical equations may better suit the rate of export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KNehsYBxFi5g"
   },
   "outputs": [],
   "source": [
    "#chosen function: power\n",
    "def linear_relation(t,m,c):\n",
    "    export = m*t + c\n",
    "    return export\n",
    "\n",
    "def dcdt(t,m,c,f_actual): #vary intercept\n",
    "    f_predicted = linear_relation(t,m,c)\n",
    "    a = np.sum(f_actual - f_predicted)\n",
    "    b = -2/len(f_actual)\n",
    "    const = a * b\n",
    "    return const\n",
    "\n",
    "def dmdt(t,m,c,f_actual): #vary gradient\n",
    "    f_predicted = linear_relation(t,m,c)\n",
    "    a = np.sum((f_actual - f_predicted) * t)\n",
    "    b = -2/len(f_actual)\n",
    "    gradient = a * b\n",
    "    return gradient\n",
    "\n",
    "def get_lineEqn(m, c, t, f_i, max_iter=10000, lr = 1e-4, tol = 1e-5):\n",
    "    for _ in range(max_iter):\n",
    "        diff1 = dcdt(t,m,c,f_i)*lr\n",
    "        diff2 = dmdt(t,m,c,f_i)*lr\n",
    "        if abs(diff1) < tol and abs(diff2) < tol:\n",
    "            break\n",
    "        else:\n",
    "            c-=diff1\n",
    "            m-=diff2\n",
    "    return m,c\n",
    "\n",
    "def rss(y_predicted, y_actual):\n",
    "    return np.sum((y_actual-y_predicted)**2)\n",
    "\n",
    "def tss(y_predicted, y_actual):\n",
    "    y_ave = np.average(y_actual)\n",
    "    return np.sum((y_predicted-y_ave)**2)\n",
    "\n",
    "def r2calc(y1, ya):\n",
    "    r2 = 1 - (rss(y1,ya)/tss(y1,ya))\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IqMXSRZbFoY1"
   },
   "outputs": [],
   "source": [
    "# We are calling both scipy's linear regression function, and our own linear\n",
    "# regression model that is seen in get_lineEqn().\n",
    "for key in region_of_interest.keys():\n",
    "    for i in range(len(region_of_interest[key])):\n",
    "        heat_map = overlay_threshold(key, vf_dict[key], region_of_interest[key][i], return_base = False)\n",
    "        weighted_fluorescence = extract_Data(key, vf_dict[key], region_of_interest[key][i], power_overlay(heat_map))\n",
    "        weighted_fluorescence = weighted_fluorescence/np.max(weighted_fluorescence)\n",
    "        max_index = np.where(weighted_fluorescence == np.max(weighted_fluorescence))\n",
    "        export = weighted_fluorescence[max_index[0][0]:]\n",
    "        frames = np.arange(max_index[0][0],len(weighted_fluorescence))\n",
    "        t = (np.arange(1,len(export)+1))*5\n",
    "        plt.figure(figsize = (10,4))\n",
    "        plt.grid(alpha = 0.25)\n",
    "        plt.plot(frames, export, '.')\n",
    "        plt.title(f'{key} \\nRegion of Interest {i} \\n{region_of_interest[key][i]}')\n",
    "\n",
    "        function = linregress(t,export, alternative = 'less')\n",
    "        line = linear_relation(t, function.slope, function.intercept)\n",
    "        plt.plot(frames, line, label = r'export = {:.3f}t + {:.3f}, $r^2$ = {:.3f}'.format(function.slope,function.intercept,function.rvalue**2))\n",
    "\n",
    "        m, c = get_lineEqn(m=-1,c=1, t=t, f_i = export)\n",
    "        my_line = linear_relation(t,m,c)\n",
    "        r2 = r2calc(my_line, export)\n",
    "        plt.plot(frames, my_line, label = r'export = {:.3f}t + {:.3f}, $r^2$ = {:.3f}'.format(m, c, r2), linestyle = 'dashed')\n",
    "        plt.legend(loc = 'upper right')\n",
    "        plt.xlabel('Frame Number')\n",
    "        plt.ylabel('Relative fluorescence', rotation = 90)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JHtJasJtFtRU"
   },
   "outputs": [],
   "source": [
    "# this shows the heat maps\n",
    "for key in region_of_interest.keys():\n",
    "    for i in range(len(region_of_interest[key])):\n",
    "        heat_map = overlay_threshold(key, vf_dict[key], region_of_interest[key][i], return_base = False)\n",
    "        plt.imshow(heat_map, cmap = 'jet')\n",
    "        plt.axis('off')\n",
    "        plt.colorbar()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tm1_YRDGFyA8"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "key = '0.5ugDNA_drug10uM_5min45min_1'\n",
    "video1 = extract_fluorescenceData(key, vf_dict[key], region_of_interest[key][i])\n",
    "\n",
    "#first overlay without any configuration to heat map\n",
    "img_overlay, overlay = overlay_threshold(key, vf_dict[key], region_of_interest[key][i])\n",
    "img_overlay = img_overlay/max(img_overlay)\n",
    "\n",
    "#increasing the heat map by power of 4, not 2. squared is just an old name and im lazy\n",
    "overlay1 = power_overlay(overlay)\n",
    "img_squared = extract_Data(key, vf_dict[key], region_of_interest[key][i], overlay1)\n",
    "img_squared = img_squared/max(img_squared)\n",
    "\n",
    "#this is normalising the heat map, but it does the same as the first function\n",
    "overlay2 = norm_overlay(overlay)\n",
    "img_norm = extract_Data(key, vf_dict[key], region_of_interest[key][i], overlay2)\n",
    "img_norm = img_norm/max(img_norm)\n",
    "\n",
    "#fluorescence of ratio\n",
    "ratio_f = ratio_Data(key, vf_dict[key], region_of_interest[key][i])\n",
    "ratio_f = ratio_f/max(ratio_f)\n",
    "\n",
    "img_mask = extract_thresholdData(key, vf_dict[key], region_of_interest[key][i], golgi_frame[key])\n",
    "img_mask = img_mask/max(img_mask)\n",
    "\n",
    "threshold_weighted = extract_Data(key, vf_dict[key], region_of_interest[key][i], overlay1,\n",
    "                                  use_threshold = True, reference = golgi_frame[key])\n",
    "threshold_weighted = threshold_weighted/max(threshold_weighted)\n",
    "\n",
    "frames = np.arange(1,len(img_overlay)+1)\n",
    "plt.figure(figsize = (12,4))\n",
    "plt.plot(frames, img_overlay, label = \"Linear\", linestyle = 'solid', marker = '*')\n",
    "plt.plot(frames, img_squared, label = \"Powered\", linestyle = 'solid', marker = 'v')\n",
    "plt.plot(frames, ratio_f, label = 'Fluorescence/Area', linestyle = 'solid', marker = 's')\n",
    "plt.plot(frames, img_mask, label = 'Threshold', linestyle = 'solid', marker = 'p')\n",
    "plt.plot(frames, threshold_weighted, label = \"Threshold and Power weight\", linestyle = 'solid', marker = 'P')\n",
    "histogrammer(video1, key, label = True) #reusing previous code\n",
    "plt.title(f'{key} Region of Interest {i}')\n",
    "plt.legend(loc = 'upper right', bbox_to_anchor = (1.38,1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{key} Region of Interest {i}', format = \"jpg\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
